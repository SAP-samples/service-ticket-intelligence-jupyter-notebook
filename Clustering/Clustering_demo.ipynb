{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Demo\n",
    "\n",
    "In this notebook, we will see how to prepare the data for clustering, upload the data, start training and do inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependent libraries if not already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyjwt\n",
    "!pip install circlify\n",
    "!pip install colorspacious\n",
    "!pip install matplotlib\n",
    "!pip install squarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import jwt\n",
    "import requests\n",
    "import base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data\n",
    "\n",
    "We have a small dataset of mixed content. The dataset contains labels regarding the topics, but we will take an unsupervised learning approach. The labels will be ignored during training, only during inference, we will use the labels to evaluate the content of each clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code block loads the data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/clustering_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's select the input and output mappings for training\n",
    "\n",
    "The mapping describes which columns in the upload file should be used as sample input and which ones are to be saved and retrieved during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = ['title','content']\n",
    "output_cols = [\"id\",'title','label']\n",
    "all_cols = input_cols + output_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STI REST Endpoints\n",
    "\n",
    "The STI service can be accessed and controlled through REST endpoint.\n",
    "Documentation can be found in the following link: https://help.sap.com/viewer/product/SERVICE_TICKET_INTELLIGENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscription and Authentication\n",
    "\n",
    "Now we are ready to train a model using the Service Ticket Intelligence API. This requires a valid subscription to the STI API.\n",
    "\n",
    "Note: Download the service key for STI and upload it to project root as `default_key.json`. This config file is placed one directory above this notebook. These values will be available in `service_keys` of your STI instance in the cloud foundry cockpit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import clustering_functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # import importlib\n",
    " # importlib.reload(clustering_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STI_BASE_DIR = Path.cwd().parent\n",
    "config_file_path = STI_BASE_DIR / 'default_key.json'\n",
    "\n",
    "connection = clustering_functions.get_connection_object(config_file=config_file_path)\n",
    "sti = clustering_functions.STIFunctions(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List models\n",
    "\n",
    "Now lets do list model call using this python function to view all the models in this account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sti.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File upload\n",
    "\n",
    "This process will take a few minutes to complete depending on the file size. If file upload is successful, the response text will contain a model id - an UUID identifier which we can use as a reference to the uploaded training file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "payload = {\n",
    "    \"scenario\": {\n",
    "        \"desc\": \"testing data for clustering\",\n",
    "        \"type\": \"clustering\",\n",
    "        \"language\": \"en\",\n",
    "        \"business_object\": \"ticket\",\n",
    "    },\n",
    "    \"mapping\": {\n",
    "        \"input\": input_cols,\n",
    "        \"output\": output_cols\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"file\": \"{}\".format(\n",
    "            base64.b64encode(df.to_csv(index=False).encode(\"utf-8\")).decode(\"utf-8\")\n",
    "        )\n",
    "    },\n",
    "}\n",
    "\n",
    "response = sti.file_upload(payload)\n",
    "our_model_id = response.get(\"model_id\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training on uploaded file\n",
    "\n",
    "Take the model id from file upload response text and pass it when in starting the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# our_model_id = '763f5e0f9ec5484191dad6540ac30814'\n",
    "\n",
    "sti.start_model_training(model_id=our_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait for training to succeed\n",
    "\n",
    "After starting the model training, do a get model status and check if model status is `READY`\n",
    "\n",
    "The model status transitions from `NEW` to `PENDING_TRAINING` once training is submitted and will further transition to `IN_TRAINING` and finally `READY` when training succeeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for model status to be `READY` before proceeding to next step. This will take up to 10-20 mins from the training submission time. Repeatedly run the above cell to get the latest model status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model status is `READY` proceed to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# our_model_id = \"2fc0bb96169741b5b2950354210961a8\"\n",
    "\n",
    "status = sti.get_model_status(model_id=our_model_id)\n",
    "status[\"model_status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate the model\n",
    "\n",
    "Once model training is completed, model needs to activated before inference can be run on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our_model_id = \"2fc0bb96169741b5b2950354210961a8\"\n",
    "\n",
    "status = sti.activate_model(model_id=our_model_id)\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's send some inference request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve all the clusters in the training dataset. They have been saved together with the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inference_payload = {}\n",
    "    \n",
    "inference_response = sti.clustering(data_payload=inference_payload)\n",
    "len(inference_response[\"en\"][\"clusters\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve cluster based on filter of top k cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference_payload = {\n",
    "\n",
    "   \"options\":{\n",
    "      \"top_k_clusters\":10\n",
    "   }\n",
    "}\n",
    "\n",
    "inference_response = sti.clustering(data_payload=inference_payload)\n",
    "len(inference_response[\"en\"][\"clusters\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve cluster based on filter of groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_payload = {\n",
    "    \"options\": {\n",
    "    \"language\": \"en\",\n",
    "    \"cluster_groupby\" : {\"column\" : \"label\",\n",
    "                     \"value\" :  [\"crypto\"]}\n",
    "    }\n",
    "}\n",
    "\n",
    "inference_response = sti.clustering(data_payload=inference_payload)\n",
    "len(inference_response[\"en\"][\"clusters\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = inference_response.copy()\n",
    "sti.clustering_plot_treemap(clusters = clusters,lang = \"en\",top_k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clusters = inference_response.copy()\n",
    "sti.clustering_plot_circlepacking(clusters = clusters,lang = \"en\",top_k=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deactivate model\n",
    "\n",
    "We can deactivate any active models here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sti.deactivate_model(model_id=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete model\n",
    "\n",
    "We can delete any unused models here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sti.delete_model(model_id=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
